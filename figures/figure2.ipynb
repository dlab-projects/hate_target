{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656df86-47d2-4af0-a8b2-9395be28d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_lego as mplego\n",
    "import numpy as np\n",
    "\n",
    "from hate_target import utils\n",
    "from mpl_lego.labels import bold_text, apply_subplot_labels\n",
    "from pyprojroot import here\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c0b07-f76c-4e06-b7b5-98e7d8405aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplego.style.use_latex_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e085e-f4af-4bb2-aea6-693c6b47988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_race = utils.analyze_experiment(\n",
    "    path=here('experiments/figure2a_results.pkl'),\n",
    "    soft=True,\n",
    "    verbose=True,\n",
    "    thresholds=[0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84488028",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_gender = utils.analyze_experiment(\n",
    "    path=here('experiments/figure2b_results.pkl'),\n",
    "    soft=True,\n",
    "    verbose=True,\n",
    "    thresholds=[0.5, 0.25, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of identity groups\n",
    "n_race_groups = analysis_race['roc_aucs'].shape[1]\n",
    "# Calculate incidence rates for race\n",
    "incidence_race = analysis_race['incidence_rate']\n",
    "# Sort incidence rates by magnitude for figure\n",
    "sorted_race_idx = np.flip(np.argsort(incidence_race))\n",
    "# Generate labels for plot\n",
    "labels_race = bold_text([\n",
    "    'Asian',\n",
    "    'Black',\n",
    "    'Latinx',\n",
    "    'Middle Eastern',\n",
    "    'Native American',\n",
    "    'Other',\n",
    "    'Pacific Islander',\n",
    "    'White'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19b842-e142-4153-98f4-ee3041e45dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of identity groups\n",
    "analysis_gender = utils.analyze_experiment(\n",
    "    here('experiments/figure2b_results.pkl'),\n",
    "    soft=True,\n",
    "    verbose=True,\n",
    "    thresholds=[0.5, 0.25, 0.5, 0.5])\n",
    "incidence_gender = analysis_gender['incidence_rate']\n",
    "sorted_gender = np.flip(np.argsort(incidence_gender))\n",
    "n_gender_groups = analysis_gender['roc_aucs'].shape[1]\n",
    "# Calculate incidence rates for gender\n",
    "incidence_gender = analysis_gender['incidence_rate']\n",
    "# Sort incidence rates by magnitude for figure\n",
    "sorted_gender_idx = np.flip(np.argsort(incidence_gender))\n",
    "# Generate labels for plot\n",
    "labels_gender = bold_text([\n",
    "    'Men',\n",
    "    'Non-Binary',\n",
    "    'Transgender',\n",
    "    'Women'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary metrics for Figure 2a\n",
    "precision_race_mean = analysis_race['precision'].mean(axis=0)[sorted_race_idx]\n",
    "precision_race_std = np.std(analysis_race['precision'], axis=0)[sorted_race_idx]\n",
    "recall_race_mean = analysis_race['recall'].mean(axis=0)[sorted_race_idx]\n",
    "recall_race_std = np.std(analysis_race['recall'], axis=0)[sorted_race_idx]\n",
    "f1_race_mean = analysis_race['f1_scores'].mean(axis=0)[sorted_race_idx]\n",
    "f1_race_std = np.std(analysis_race['f1_scores'], axis=0)[sorted_race_idx]\n",
    "# Calculate summary metrics for Figure 2b\n",
    "roc_auc_race_mean = analysis_race['roc_aucs'].mean(axis=0)[sorted_race_idx]\n",
    "roc_auc_race_std = np.std(analysis_race['roc_aucs'], axis=0)[sorted_race_idx]\n",
    "pr_auc_race_mean = analysis_race['pr_aucs'].mean(axis=0)[sorted_race_idx]\n",
    "pr_auc_race_std = np.std(analysis_race['pr_aucs'], axis=0)[sorted_race_idx]\n",
    "# Calculate summary metrics for Figure 2c\n",
    "precision_gender_mean = analysis_gender['precision'].mean(axis=0)[sorted_gender_idx]\n",
    "precision_gender_std = np.std(analysis_gender['precision'], axis=0)[sorted_gender_idx]\n",
    "recall_gender_mean = analysis_gender['recall'].mean(axis=0)[sorted_gender_idx]\n",
    "recall_gender_std = np.std(analysis_gender['recall'], axis=0)[sorted_gender_idx]\n",
    "f1_gender_mean = analysis_gender['f1_scores'].mean(axis=0)[sorted_gender_idx]\n",
    "f1_gender_std = np.std(analysis_gender['f1_scores'], axis=0)[sorted_gender_idx]\n",
    "# Calculate summary metrics for Figure 2d\n",
    "roc_auc_gender_mean = analysis_gender['roc_aucs'].mean(axis=0)[sorted_gender_idx]\n",
    "roc_auc_gender_std = np.std(analysis_gender['roc_aucs'], axis=0)[sorted_gender_idx]\n",
    "pr_auc_gender_mean = analysis_gender['pr_aucs'].mean(axis=0)[sorted_gender_idx]\n",
    "pr_auc_gender_std = np.std(analysis_gender['pr_aucs'], axis=0)[sorted_gender_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c430a1-23b2-4b25-9072-a0256d91191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Figure 2:\n",
    "Model performance on target identity sub-groups\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 7))\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.8)\n",
    "\n",
    "# Colors\n",
    "precision_color = 'C0'\n",
    "recall_color = 'C1'\n",
    "f1_color = 'C2'\n",
    "roc_auc_color = 'C4'\n",
    "pr_auc_color = 'lightgrey'\n",
    "# Bar plot settings\n",
    "center_points_race = np.arange(n_race_groups)\n",
    "center_points_gender = np.arange(n_gender_groups)\n",
    "fig_2a_bar_width = 0.30\n",
    "fig_2b_bar_width = 0.40\n",
    "fig2c_bar_width = 0.3\n",
    "fig2d_bar_width = 0.4\n",
    "fig_2a_cap_size = 2\n",
    "fig_2b_cap_size = 3\n",
    "fig2c_cap_size = 2\n",
    "fig2d_cap_size = 3\n",
    "bar_edge_color = 'black'\n",
    "incidence_color = 'black'\n",
    "# Size settings\n",
    "incidence_lw = 2.5\n",
    "subplot_label_size = 20\n",
    "legend_size = 12\n",
    "xtick_rotation = 20\n",
    "xtick_size = 13\n",
    "xlabel_size = 16\n",
    "ylabel_size = 15\n",
    "tick_label_size = 14\n",
    "\n",
    "\"\"\"\n",
    "Figure 2a:\n",
    "Precision, recall, and F1 score across race sub-groups\n",
    "\"\"\"\n",
    "# Precision bar plot\n",
    "axes[0, 0].bar(\n",
    "    x=center_points_race - fig_2a_bar_width,\n",
    "    height=precision_race_mean,\n",
    "    width=fig_2a_bar_width,\n",
    "    yerr=precision_race_std,\n",
    "    color=precision_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig_2a_cap_size},\n",
    "    label='Precision')\n",
    "# Recall bar plot\n",
    "axes[0, 0].bar(\n",
    "    x=center_points_race,\n",
    "    height=recall_race_mean,\n",
    "    width=fig_2a_bar_width,\n",
    "    yerr=recall_race_std,\n",
    "    color=recall_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig_2a_cap_size},\n",
    "    label='Recall')\n",
    "# F1 score bar plot\n",
    "axes[0, 0].bar(\n",
    "    x=center_points_race + fig_2a_bar_width,\n",
    "    height=f1_race_mean,\n",
    "    width=fig_2a_bar_width,\n",
    "    yerr=f1_race_std,\n",
    "    color=f1_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig_2a_cap_size},\n",
    "    label='F1 Score')\n",
    "\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "axes[0, 0].grid(axis='y')\n",
    "axes[0, 0].set_axisbelow(True)\n",
    "axes[0, 0].legend(\n",
    "    bbox_to_anchor=(0.5, 1.08),\n",
    "    loc='center',\n",
    "    ncol=3,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "\"\"\"\n",
    "Figure 2b:\n",
    "ROC / PR AUC scores across race sub-groups\n",
    "\"\"\"\n",
    "# ROC AUC bar plot\n",
    "axes[0, 1].bar(\n",
    "    x=center_points_race - fig_2b_bar_width / 2,\n",
    "    height=roc_auc_race_mean,\n",
    "    width=fig_2b_bar_width,\n",
    "    yerr=roc_auc_race_std,\n",
    "    color=roc_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig_2b_cap_size},\n",
    "    label='ROC AUC')\n",
    "# PR AUC bar plot\n",
    "axes[0, 1].bar(\n",
    "    x=center_points_race + fig_2b_bar_width / 2,\n",
    "    height=pr_auc_race_mean,\n",
    "    width=fig_2b_bar_width,\n",
    "    yerr=pr_auc_race_std,\n",
    "    color=pr_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig_2b_cap_size},\n",
    "    label='PR AUC')\n",
    "\n",
    "# Plot incidence rates for each PR AUC\n",
    "for idx, rate in enumerate(analysis_race['incidence_rate'][sorted_race_idx]):\n",
    "    axes[0, 1].plot(\n",
    "        [idx + fig_2b_bar_width, idx],\n",
    "        [rate, rate],\n",
    "        color=incidence_color,\n",
    "        lw=incidence_lw)\n",
    "\n",
    "axes[0, 1].legend(\n",
    "    bbox_to_anchor=(0.5, 1.08),\n",
    "    loc='center',\n",
    "    ncol=2,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "\"\"\"\n",
    "Figure 2c:\n",
    "Precision, recall, and F1 score across gender sub-groups\n",
    "\"\"\"\n",
    "# Precision bar plot\n",
    "axes[1, 0].bar(\n",
    "    x=center_points_gender - fig2c_bar_width,\n",
    "    height=precision_gender_mean,\n",
    "    width=fig2c_bar_width,\n",
    "    yerr=precision_gender_std,\n",
    "    color=precision_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig2c_cap_size},\n",
    "    label='Precision')\n",
    "# Recall bar plot\n",
    "axes[1, 0].bar(\n",
    "    x=center_points_gender,\n",
    "    height=recall_gender_mean,\n",
    "    width=fig2c_bar_width,\n",
    "    yerr=recall_gender_std,\n",
    "    color=recall_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig2c_cap_size},\n",
    "    label='Recall')\n",
    "# F1 score bar plot\n",
    "axes[1, 0].bar(\n",
    "    x=center_points_gender + fig2c_bar_width,\n",
    "    height=f1_gender_mean,\n",
    "    width=fig2c_bar_width,\n",
    "    yerr=f1_gender_std,\n",
    "    color=f1_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig2c_cap_size},\n",
    "    label='F1 Score')\n",
    "\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].grid(axis='y')\n",
    "axes[1, 0].set_axisbelow(True)\n",
    "axes[1, 0].legend(\n",
    "    bbox_to_anchor=(0.5, 1.08),\n",
    "    loc='center',\n",
    "    ncol=3,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "\"\"\"\n",
    "Figure 2d:\n",
    "ROC / PR AUC scores across gender sub-groups\n",
    "\"\"\"\n",
    "# ROC AUC bar plot\n",
    "axes[1, 1].bar(\n",
    "    x=center_points_gender - fig2d_bar_width / 2,\n",
    "    height=roc_auc_gender_mean,\n",
    "    width=fig2d_bar_width,\n",
    "    yerr=roc_auc_gender_std,\n",
    "    color=roc_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig2d_cap_size},\n",
    "    label='ROC AUC')\n",
    "# PR AUC bar plot\n",
    "axes[1, 1].bar(\n",
    "    x=center_points_gender + fig2d_bar_width / 2,\n",
    "    height=pr_auc_gender_mean,\n",
    "    width=fig2d_bar_width,\n",
    "    yerr=pr_auc_gender_std,\n",
    "    color=pr_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig2d_cap_size},\n",
    "    label='PR AUC')\n",
    "\n",
    "axes[1, 1].legend(\n",
    "    bbox_to_anchor=(0.5, 1.08),\n",
    "    loc='center',\n",
    "    ncol=2,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "# Plot incidence rates for each PR AUC\n",
    "for idx, rate in enumerate(analysis_gender['incidence_rate'][sorted_gender_idx]):\n",
    "    axes[1, 1].plot(\n",
    "        [idx + fig2d_bar_width, idx],\n",
    "        [rate, rate],\n",
    "        color=incidence_color,\n",
    "        lw=incidence_lw)\n",
    "\n",
    "\"\"\"\n",
    "Figure 2 labels and ticks\n",
    "\"\"\"\n",
    "# Top row labels and ticks\n",
    "for ax in axes[0]:\n",
    "    ax.set_xticks(np.arange(n_race_groups))\n",
    "    ax.set_xticklabels(\n",
    "        bold_text(np.array(labels_race)[sorted_race_idx]),\n",
    "        ha='right',\n",
    "        rotation=xtick_rotation,\n",
    "        fontsize=xtick_size)\n",
    "    ax.set_xlabel(bold_text('Race Sub-Groups'), fontsize=xlabel_size)\n",
    "# Bottom row labels and ticks\n",
    "for ax in axes[1]:\n",
    "    ax.set_xticks(np.arange(n_gender_groups))\n",
    "    ax.set_xticklabels(\n",
    "        bold_text(np.array(labels_gender)[sorted_gender_idx]),\n",
    "        ha='right',\n",
    "        rotation=xtick_rotation,\n",
    "        fontsize=xtick_size)\n",
    "    ax.set_xlabel(bold_text('Gender Sub-Groups'), fontsize=xlabel_size)\n",
    "# Left column y-axis labels\n",
    "for ax in axes[:, 0]:\n",
    "    ax.set_ylabel(bold_text('Metric'), fontsize=ylabel_size)\n",
    "# General plot ticks and sizes\n",
    "for ax in axes.ravel():\n",
    "    ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    ax.set_ylim([0, 1.03])\n",
    "    ax.grid(axis='y')\n",
    "    # Needs this twice, for some reason\n",
    "    ax.grid(axis='y')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.tick_params(labelsize=tick_label_size)\n",
    "# Apply subplot labels\n",
    "apply_subplot_labels(\n",
    "    axes,\n",
    "    bold=True,\n",
    "    x=-0.04,\n",
    "    y=1.09,\n",
    "    size=subplot_label_size)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('figure2.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate",
   "language": "python",
   "name": "hate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
