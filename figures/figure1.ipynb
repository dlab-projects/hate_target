{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656df86-47d2-4af0-a8b2-9395be28d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_lego as mplego\n",
    "import numpy as np\n",
    "\n",
    "from hate_target import keys, utils\n",
    "from mpl_lego.labels import bold_text, apply_subplot_labels\n",
    "from pyprojroot import here\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c0b07-f76c-4e06-b7b5-98e7d8405aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplego.style.use_latex_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = here('experiments/figure1_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e085e-f4af-4bb2-aea6-693c6b47988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiment results\n",
    "analysis = utils.analyze_experiment(results_path, soft=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed528fd6-e1b7-44be-b8be-543d9eaead18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of identity groups\n",
    "n_groups = analysis['roc_aucs'].shape[1]\n",
    "# Calculate incidence rates\n",
    "incidence_rates = analysis['incidence_rate']\n",
    "# Sort incidence rates by magnitude for figure\n",
    "sorted_idx = np.flip(np.argsort(incidence_rates))\n",
    "# Generate labels for plot\n",
    "labels = bold_text(sorted(keys.target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3417c9f-fa61-45ff-86e5-66a212e38fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary metrics for Figure 1\n",
    "precision_mean = analysis['precision'].mean(axis=0)[sorted_idx]\n",
    "precision_std = np.std(analysis['precision'], axis=0)[sorted_idx]\n",
    "recall_mean = analysis['recall'].mean(axis=0)[sorted_idx]\n",
    "recall_std = np.std(analysis['recall'], axis=0)[sorted_idx]\n",
    "f1_mean = analysis['f1_scores'].mean(axis=0)[sorted_idx]\n",
    "f1_std = np.std(analysis['f1_scores'], axis=0)[sorted_idx]\n",
    "roc_auc_mean = analysis['roc_aucs'].mean(axis=0)[sorted_idx]\n",
    "roc_auc_std = np.std(analysis['roc_aucs'], axis=0)[sorted_idx]\n",
    "pr_auc_mean = analysis['pr_aucs'].mean(axis=0)[sorted_idx]\n",
    "pr_auc_std = np.std(analysis['pr_aucs'], axis=0)[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c430a1-23b2-4b25-9072-a0256d91191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Figure 1:\n",
    "Transformer models are predictive of target identity groups\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "\n",
    "# Colors\n",
    "precision_color = 'C0'\n",
    "recall_color = 'C1'\n",
    "f1_color = 'C2'\n",
    "roc_auc_color = 'C4'\n",
    "pr_auc_color = 'lightgrey'\n",
    "# Bar plot settings\n",
    "center_points = np.arange(n_groups)\n",
    "fig_1a_bar_width = 0.28\n",
    "fig_1b_bar_width = 0.40\n",
    "bar_edge_color = 'black'\n",
    "fig1a_error_capsize = 2\n",
    "fig1b_error_capsize = 3\n",
    "# Size settings\n",
    "legend_size = 13\n",
    "ax_label_size = 17\n",
    "ax_tick_label_size = 14\n",
    "subplot_label_size = 18\n",
    "\n",
    "\"\"\"\n",
    "Figure 1a:\n",
    "Precision, recall, and F1 score across identity groups\n",
    "\"\"\"\n",
    "# Precision bar plot\n",
    "axes[0].bar(\n",
    "    x=center_points - fig_1a_bar_width,\n",
    "    height=precision_mean,\n",
    "    width=fig_1a_bar_width,\n",
    "    yerr=precision_std,\n",
    "    color=precision_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig1a_error_capsize},\n",
    "    label='Precision')\n",
    "# Recall bar plot\n",
    "axes[0].bar(\n",
    "    x=center_points,\n",
    "    height=recall_mean,\n",
    "    width=fig_1a_bar_width,\n",
    "    yerr=recall_std,\n",
    "    color=recall_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig1a_error_capsize},\n",
    "    label='Recall')\n",
    "# F1 score bar plot\n",
    "axes[0].bar(\n",
    "    x=center_points + fig_1a_bar_width,\n",
    "    height=f1_mean,\n",
    "    width=fig_1a_bar_width,\n",
    "    yerr=f1_std,\n",
    "    color=f1_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig1a_error_capsize},\n",
    "    label='F1 Score')\n",
    "\n",
    "axes[0].set_ylim([0, 1.03])\n",
    "axes[0].set_ylabel(bold_text('Metric'), fontsize=ax_label_size)\n",
    "axes[0].grid(axis='y')\n",
    "axes[0].set_axisbelow(True)\n",
    "axes[0].legend(\n",
    "    bbox_to_anchor=(0.5, 1.06),\n",
    "    loc='center',\n",
    "    ncol=3,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "\"\"\"\n",
    "Figure 1b:\n",
    "ROC / PR AUC scores across identity groups\n",
    "\"\"\"\n",
    "# ROC AUC bar plot\n",
    "axes[1].bar(\n",
    "    x=center_points - fig_1b_bar_width / 2,\n",
    "    height=roc_auc_mean,\n",
    "    width=fig_1b_bar_width,\n",
    "    yerr=roc_auc_std,\n",
    "    color=roc_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig1b_error_capsize},\n",
    "    label='ROC AUC')\n",
    "# PR AUC bar plot\n",
    "axes[1].bar(\n",
    "    x=center_points + fig_1b_bar_width / 2,\n",
    "    height=pr_auc_mean,\n",
    "    width=fig_1b_bar_width,\n",
    "    yerr=pr_auc_std,\n",
    "    color=pr_auc_color,\n",
    "    edgecolor=bar_edge_color,\n",
    "    error_kw={'capsize': fig1b_error_capsize},\n",
    "    label='PR AUC')\n",
    "\n",
    "# Plot incidence rates for each PR AUC\n",
    "for idx, rate in enumerate(incidence_rates[sorted_idx]):\n",
    "    axes[1].plot(\n",
    "        [idx + width, idx],\n",
    "        [rate, rate],\n",
    "        color='black',\n",
    "        lw=2.5)\n",
    "\n",
    "axes[1].grid(axis='y')\n",
    "axes[1].set_axisbelow(True)\n",
    "axes[1].set_ylim([0, 1.03])\n",
    "\n",
    "# Set axes ticks and labels\n",
    "for ax in axes:\n",
    "    ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    ax.set_xticks(np.arange(n_groups))\n",
    "    ax.set_xticklabels(\n",
    "        np.array(bold_text(sorted(keys.target_labels)))[sorted_idx],\n",
    "        ha='right',\n",
    "        rotation=20)\n",
    "    ax.tick_params(labelsize=ax_tick_label_size)\n",
    "\n",
    "# Create legend\n",
    "axes[1].legend(\n",
    "    bbox_to_anchor=(0.5, 1.06),\n",
    "    loc='center',\n",
    "    ncol=2,\n",
    "    prop={'size': legend_size})\n",
    "\n",
    "# Apply subplot labels\n",
    "apply_subplot_labels(\n",
    "    axes,\n",
    "    bold=True,\n",
    "    x=-0.04,\n",
    "    y=1.07,\n",
    "    size=subplot_label_size)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('figure1.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate",
   "language": "python",
   "name": "hate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
