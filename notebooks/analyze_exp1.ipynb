{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03f77e-3caf-43ea-824a-ce3f74d067a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_lego as mplego\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pyprojroot import here\n",
    "from hate_target import keys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from mpl_lego.labels import bold_text\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fae94-5bc2-4ece-833e-cf5f0e10e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplego.style.use_latex_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7725ab-3881-450a-b9b3-e182c8d92c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(keys.target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cc49f-0b74-4cad-9203-7d12010b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "comment_id = 'comment_id'\n",
    "text_col = 'predict_text'\n",
    "threshold = 0.5\n",
    "\n",
    "# Read in data\n",
    "data_path = \"~/data/hatespeech/unfiltered_ratings.feather\"\n",
    "data = pd.read_feather(data_path)\n",
    "comments = data[[comment_id, text_col]].drop_duplicates().sort_values(comment_id)\n",
    "# Determine target identities\n",
    "agreement = data[[comment_id] + keys.target_groups].groupby(comment_id).agg('mean')\n",
    "is_target = (agreement >= threshold).astype('int').reset_index(level=0).merge(right=comments, how='left')\n",
    "# Extract data for training models\n",
    "x = is_target[text_col].values\n",
    "identities = agreement[sorted(keys.target_groups)]\n",
    "y = [identities[col].values.astype('int')[..., np.newaxis] for col in identities]\n",
    "\n",
    "n_groups = len(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a14f4-b5b4-43af-81d8-16d518cb6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = here('experiments/exp1_use_v4_h64_b32_d4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc2a16-b867-4a32-83e0-981826e5478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(exp_path, 'rb') as file:\n",
    "    n_epochs, train_idxs, test_idxs, test_predictions, test_scores, chance = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96005b59-6beb-43b6-82c8-da4d27676d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = test_scores[:, 9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0e616-9caa-4c83-8d5d-b8d45c11a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_over_chance = test_accs / chance\n",
    "avg_acc_over_chance = np.mean(acc_over_chance, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dbcbf-7560-4a5e-bf34-dddc7bece036",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds_diff = np.log(test_accs / (1 - test_accs)) - np.log(chance / (1 - chance))\n",
    "avg_log_odds_diff = np.mean(log_odds_diff, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70d4d3-d9fd-41b0-9dbc-50ff924eb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "axes[0].barh(-np.arange(n_groups), avg_acc_over_chance)\n",
    "axes[1].barh(-np.arange(n_groups), avg_log_odds_diff)\n",
    "\n",
    "axes[0].set_xlim([1.0, 1.05])\n",
    "for ax in axes:\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_yticks(-np.arange(n_groups))\n",
    "    ax.set_yticklabels(bold_text(sorted_labels))\n",
    "    \n",
    "axes[0].set_xlabel(bold_text('Accuracy / Chance'), fontsize=17)\n",
    "axes[1].set_xlabel(bold_text('Log-Odds Difference'), fontsize=17)\n",
    "plt.savefig('accuracies.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56e8e1-e1bc-471a-8814-eecd99bfc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_rocs = np.array([roc_auc_score(y[i].ravel(), test_predictions[i].ravel()) for i in range(n_groups)])\n",
    "auc_prcs = np.array([average_precision_score(y[i].ravel(), test_predictions[i].ravel()) for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262505e-e82c-49c5-94ca-29b6790ee5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "axes[0].barh(-np.arange(n_groups), auc_rocs)\n",
    "axes[1].barh(-np.arange(n_groups), auc_prcs)\n",
    "\n",
    "axes[0].set_xlim([0.8, 1.0])\n",
    "axes[1].set_xlim([0, 0.35])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_yticks(-np.arange(n_groups))\n",
    "    ax.set_yticklabels(bold_text(sorted_labels))\n",
    "    \n",
    "axes[0].set_xlabel(bold_text('ROC-AUC'), fontsize=17)\n",
    "axes[1].set_xlabel(bold_text('PR-AUC'), fontsize=17)\n",
    "\n",
    "plt.savefig('aucs.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81281112-f162-4027-8455-4319d0166ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hate",
   "language": "python",
   "name": "hate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
